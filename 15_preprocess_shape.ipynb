{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 09:53:21.650063: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 09:53:21.876529: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-30 09:53:22.549730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-30 09:53:22.549825: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-30 09:53:22.549834: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow V2.11.0\n",
      "Keras V2.11.0\n",
      "Python V3.7.11 (default, Jul 27 2021, 14:32:16) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "\n",
    "print(f'Tensorflow V{tf.__version__}')\n",
    "print(f'Keras V{tf.keras.__version__}')\n",
    "print(f'Python V{sys.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"base_fix_32\"\n",
    "out_root = f\"./processed_data/{target}/\"\n",
    "os.makedirs(out_root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def setLogger(output_path):\n",
    "    logging_outfile = output_path + \"/logger.log\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"[%(asctime)s][%(name)s][%(funcName)s][%(levelname)s] %(message)s\",\n",
    "        filename=str(logging_outfile),\n",
    "        filemode=\"w\"\n",
    "    )\n",
    "    logger = logging.getLogger(__name__)\n",
    "    #logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    ## sets up stream handler\n",
    "    shandler = logging.StreamHandler()\n",
    "    shandler.setLevel(logging.INFO)\n",
    "\n",
    "    ## sets up formatter\n",
    "    formatter = logging.Formatter(\"[%(asctime)s][%(name)s][%(funcName)s][%(levelname)s] %(message)s\")\n",
    "    shandler.setFormatter(formatter)\n",
    "\n",
    "    ## adds handlers to logger\n",
    "    logger.addHandler(shandler)\n",
    "    return logger\n",
    "\n",
    "logger = setLogger(out_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MatplotLib Global Settings\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['axes.titlesize'] = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, processing data from scratch\n",
    "# If False, loads preprocessed data\n",
    "PREPROCESS_DATA = False\n",
    "TRAIN_MODEL = True\n",
    "# True: use all data for training -> gives better LB result\n",
    "USE_VAL = True\n",
    "\n",
    "N_ROWS = 543\n",
    "N_DIMS = 3\n",
    "DIM_NAMES = ['x', 'y', 'z']\n",
    "SEED = 4949\n",
    "NUM_CLASSES = 250\n",
    "# IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n",
    "VERBOSE = 1 \n",
    "IS_INTERACTIVE=False\n",
    "\n",
    "INPUT_SIZE = 32\n",
    "\n",
    "BATCH_ALL_SIGNS_N = 4\n",
    "BATCH_SIZE = 256\n",
    "N_EPOCHS = 100\n",
    "LR_MAX = 1e-3\n",
    "N_WARMUP_EPOCHS = 0\n",
    "WD_RATIO = 0.05\n",
    "MASK_VAL = 4237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'preprocess_data': PREPROCESS_DATA,\n",
    "    'train_model': TRAIN_MODEL,\n",
    "    'use_val': USE_VAL,\n",
    "    'n_rows': N_ROWS,\n",
    "    'n_dims': N_DIMS,\n",
    "    'dim_names': DIM_NAMES,\n",
    "    'seed': SEED,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'verbose': VERBOSE,\n",
    "    'is_interactive': IS_INTERACTIVE,\n",
    "    'input_size': INPUT_SIZE,\n",
    "    'batch_all_signs_n': BATCH_ALL_SIGNS_N,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'n_epochs': N_EPOCHS,\n",
    "    'lr_max': LR_MAX,\n",
    "    'n_warmup_epochs': N_WARMUP_EPOCHS,\n",
    "    'wd_ratio': WD_RATIO,\n",
    "    'mask_val': MASK_VAL\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-30 09:53:24,374][__main__][<module>][INFO] {'preprocess_data': False, 'train_model': True, 'use_val': True, 'n_rows': 543, 'n_dims': 3, 'dim_names': ['x', 'y', 'z'], 'seed': 4949, 'num_classes': 250, 'verbose': 1, 'is_interactive': False, 'input_size': 32, 'batch_all_signs_n': 4, 'batch_size': 256, 'n_epochs': 100, 'lr_max': 0.001, 'n_warmup_epochs': 0, 'wd_ratio': 0.05, 'mask_val': 4237}\n"
     ]
    }
   ],
   "source": [
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints Shape and Dtype For List Of Variables\n",
    "def print_shape_dtype(l, names):\n",
    "    for e, n in zip(l, names):\n",
    "        print(f'{n} shape: {e.shape}, dtype: {e.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_SAMPLES: 94477\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/home/jovyan/pvc-nfs-skobayashi/competition/kaggle/2023_kaggle_gislr/data/kaggle/train.csv')\n",
    "\n",
    "N_SAMPLES = len(train)\n",
    "print(f'N_SAMPLES: {N_SAMPLES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ordinally Encoded Sign (assign number to each sign name)\n",
    "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "\n",
    "# Dictionaries to translate sign <-> ordinal encoded sign\n",
    "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>sign_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94472</th>\n",
       "      <td>train_landmark_files/53618/999786174.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>999786174</td>\n",
       "      <td>white</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94473</th>\n",
       "      <td>train_landmark_files/26734/999799849.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>999799849</td>\n",
       "      <td>have</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94474</th>\n",
       "      <td>train_landmark_files/25571/999833418.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>999833418</td>\n",
       "      <td>flower</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>train_landmark_files/29302/999895257.parquet</td>\n",
       "      <td>29302</td>\n",
       "      <td>999895257</td>\n",
       "      <td>room</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94476</th>\n",
       "      <td>train_landmark_files/36257/999962374.parquet</td>\n",
       "      <td>36257</td>\n",
       "      <td>999962374</td>\n",
       "      <td>happy</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94477 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "0      train_landmark_files/26734/1000035562.parquet           26734   \n",
       "1      train_landmark_files/28656/1000106739.parquet           28656   \n",
       "2       train_landmark_files/16069/100015657.parquet           16069   \n",
       "3      train_landmark_files/25571/1000210073.parquet           25571   \n",
       "4      train_landmark_files/62590/1000240708.parquet           62590   \n",
       "...                                              ...             ...   \n",
       "94472   train_landmark_files/53618/999786174.parquet           53618   \n",
       "94473   train_landmark_files/26734/999799849.parquet           26734   \n",
       "94474   train_landmark_files/25571/999833418.parquet           25571   \n",
       "94475   train_landmark_files/29302/999895257.parquet           29302   \n",
       "94476   train_landmark_files/36257/999962374.parquet           36257   \n",
       "\n",
       "       sequence_id    sign  sign_ord  \n",
       "0       1000035562    blow        25  \n",
       "1       1000106739    wait       232  \n",
       "2        100015657   cloud        48  \n",
       "3       1000210073    bird        23  \n",
       "4       1000240708    owie       164  \n",
       "...            ...     ...       ...  \n",
       "94472    999786174   white       238  \n",
       "94473    999799849    have       108  \n",
       "94474    999833418  flower        86  \n",
       "94475    999895257    room       188  \n",
       "94476    999962374   happy       105  \n",
       "\n",
       "[94477 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Validation\n",
    "PARTICIPANT_IDS = train['participant_id'].values\n",
    "X = train[\"path\"].values\n",
    "y = train['sign_ord'].values\n",
    "indices = train.index.values\n",
    "\n",
    "# group shuffle\n",
    "# splitter = GroupShuffleSplit(test_size=0.20, n_splits=2, random_state=SEED)\n",
    "# train_idxs, val_idxs = next(splitter.split(X, y, groups=PARTICIPANT_IDS))\n",
    "\n",
    "# random shuffle\n",
    "_, _, _, _, train_idxs, val_idxs = train_test_split(X, y, indices, test_size=0.2, random_state=SEED)\n",
    "\n",
    "train[\"valid\"] = False\n",
    "train.loc[val_idxs, \"valid\"]=True\n",
    "\n",
    "train.to_csv(f\"{out_root}/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75581, 18896)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idxs), len(val_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'/home/jovyan/pvc-nfs-skobayashi/competition/kaggle/2023_kaggle_gislr/data/kaggle/{path}'\n",
    "\n",
    "train['file_path'] = train['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HAND_IDXS: 21, N_COLS: 83\n"
     ]
    }
   ],
   "source": [
    "USE_TYPES = ['left_hand', 'pose', 'right_hand']\n",
    "START_IDX = 468\n",
    "LIPS_IDXS0 = np.array([\n",
    "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "    ])\n",
    "LEYE_IDXS0 = np.array([\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362,\n",
    "    466, 388, 387, 386, 385, 384, 398,\n",
    "    ])\n",
    "REYE_IDXS0 = np.array([\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    246, 161, 160, 159, 158, 157, 173,\n",
    "    ])\n",
    "# Landmark indices in original data\n",
    "LEFT_HAND_IDXS0 = np.arange(468,489)\n",
    "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "LEFT_POSE_IDXS0 = np.array([500, 502, 504, 506, 508, 510])\n",
    "RIGHT_POSE_IDXS0 = np.array([501, 503, 505, 507, 509, 511])\n",
    "LANDMARK_IDXS_LEFT_DOMINANT0 = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, LEFT_POSE_IDXS0, LEYE_IDXS0))\n",
    "LANDMARK_IDXS_RIGHT_DOMINANT0 = np.concatenate((LIPS_IDXS0, RIGHT_HAND_IDXS0, RIGHT_POSE_IDXS0, REYE_IDXS0))\n",
    "HAND_IDXS0 = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n",
    "N_COLS = LANDMARK_IDXS_LEFT_DOMINANT0.size\n",
    "# Landmark indices in processed data\n",
    "LIPS_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LIPS_IDXS0)).squeeze()\n",
    "LEFT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LEFT_HAND_IDXS0)).squeeze()\n",
    "RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, RIGHT_HAND_IDXS0)).squeeze()\n",
    "HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, HAND_IDXS0)).squeeze()\n",
    "POSE_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LEFT_POSE_IDXS0)).squeeze()\n",
    "EYE_IDXS = np.argwhere(np.isin(LANDMARK_IDXS_LEFT_DOMINANT0, LEYE_IDXS0)).squeeze()\n",
    "\n",
    "print(f'# HAND_IDXS: {len(HAND_IDXS)}, N_COLS: {N_COLS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "# acceraration and verocity\n",
    "N_MOTION_VEROCITY = N_COLS*2\n",
    "print(N_MOTION_VEROCITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# HAND_IDXS: 21, POSE_IDXS: 6, LIPS_IDXS: 40, HAND_BONE_IDXS: 21, POSE_BONE_IDXS: 6, N_COLS: 353\n"
     ]
    }
   ],
   "source": [
    "# Bone indices\n",
    "#LEFT_HAND_BONE_IDXS0 = np.array([[0, 1], [0, 5], [0, 17], [1, 2], [2, 3], [3, 4], [5, 6], [5, 9], [6, 7], [7, 8], [9, 10], [9, 13], [10, 11], [11, 12], [13, 14], [13, 17], [14, 15], [15, 16], [17, 18], [18, 19], [19, 20]])\n",
    "LEFT_HAND_BONE_IDXS0 = np.array([[468, 469], [468, 473], [468, 485], [469, 470], [470, 471], [471, 472], [473, 474], [473, 477], [474, 475], [475, 476], \n",
    "                                 [477, 478], [477, 481], [478, 479], [479, 480], [481, 482], [481, 485], [482, 483], [483, 484], [485, 486], [486, 487], [487, 488]])\n",
    "RIGHT_HAND_BONE_IDXS0 = np.array([[522, 523], [522, 527], [522, 539], [523, 524], [524, 525], [525, 526], [527, 528], [527, 531], [528, 529], [529, 530], \n",
    "                                  [531, 532], [531, 535], [532, 533], [533, 534], [535, 536], [535, 539], [536, 537], [537, 538], [539, 540], [540, 541], [541, 542]])\n",
    "LEFT_POSE_BONE_IDXS0 = np.array([[500, 502], [502, 504], [504, 506], [504, 508], [504, 510], [506, 508]])\n",
    "RIGHT_POSE_BONE_IDXS0 = np.array([[501, 503], [503, 505], [505, 507], [505, 509], [505, 511], [507, 509]])\n",
    "\n",
    "LEFT_HAND_BONE_0 = LEFT_HAND_BONE_IDXS0[:, 0]\n",
    "LEFT_HAND_BONE_1 = LEFT_HAND_BONE_IDXS0[:, 1]\n",
    "RIGHT_HAND_BONE_0 = RIGHT_HAND_BONE_IDXS0[:, 0]\n",
    "RIGHT_HAND_BONE_1 = RIGHT_HAND_BONE_IDXS0[:, 1]\n",
    "LEFT_POSE_BONE_0 = LEFT_POSE_BONE_IDXS0[:, 0]\n",
    "LEFT_POSE_BONE_1 = LEFT_POSE_BONE_IDXS0[:, 1]\n",
    "RIGHT_POSE_BONE_0 = RIGHT_POSE_BONE_IDXS0[:, 0]\n",
    "RIGHT_POSE_BONE_1 = RIGHT_POSE_BONE_IDXS0[:, 1]\n",
    "\n",
    "LEFT_HAND_BONE_IDXS = np.arange(LANDMARK_IDXS_LEFT_DOMINANT0.size, LANDMARK_IDXS_LEFT_DOMINANT0.size + len(LEFT_HAND_BONE_IDXS0))\n",
    "N_COLS = LANDMARK_IDXS_LEFT_DOMINANT0.size + len(LEFT_HAND_BONE_IDXS0)\n",
    "LEFT_POSE_BONE_IDXS = np.arange(N_COLS, N_COLS + len(LEFT_POSE_BONE_IDXS0))\n",
    "N_COLS = N_COLS + len(LEFT_POSE_BONE_IDXS0)\n",
    "N_COLS += N_MOTION_VEROCITY\n",
    "\n",
    "N_COLS += len(RIGHT_HAND_BONE_IDXS0) #dist\n",
    "N_COLS += (len(RIGHT_HAND_BONE_IDXS0) -1 ) # angle\n",
    "N_COLS +=(len(RIGHT_HAND_BONE_IDXS0) -1 ) # angle velocity\n",
    "N_COLS += len(LEFT_POSE_BONE_IDXS0) #dist\n",
    "N_COLS += (len(LEFT_POSE_BONE_IDXS0) -1)# angle\n",
    "N_COLS += (len(LEFT_POSE_BONE_IDXS0) -1) # angle velocity\n",
    "\n",
    "print(f'# HAND_IDXS: {len(HAND_IDXS)}, POSE_IDXS: {len(POSE_IDXS)}, LIPS_IDXS: {len(LIPS_IDXS)}, HAND_BONE_IDXS: {len(LEFT_HAND_BONE_IDXS)}, POSE_BONE_IDXS: {len(LEFT_POSE_BONE_IDXS)}, N_COLS: {N_COLS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_HAND_SHAPE_IDXS0 = np.array([[470, 485], [472, 476], [476, 480], [480, 484], [484, 488],\n",
    "                                 [468, 472], [468, 476], [468, 480], [468, 484], [468, 488], [472, 485]])\n",
    "RIGHT_HAND_SHAPE_IDXS0 = np.array([[524, 539], [526, 530], [530, 534], [534, 538], [538, 542],\n",
    "                                  [522, 526], [522, 530], [522, 534], [522, 538], [522, 542], [526, 539]])\n",
    "\n",
    "LEFT_POSE_SHAPE_IDXS0 = np.array([[500, 504], [504, 512], [504, 501], [504, 513]])\n",
    "RIGHT_POSE_SHAPE_IDXS0 = np.array([[501, 505], [505, 513], [505, 500], [505, 512]])\n",
    "\n",
    "LEFT_HAND_SHAPE_IDXS = np.arange(N_COLS, N_COLS + len(LEFT_HAND_SHAPE_IDXS0))\n",
    "N_COLS = N_COLS + len(LEFT_HAND_SHAPE_IDXS)\n",
    "LEFT_POSE_SHAPE_IDXS = np.arange(N_COLS, N_COLS + len(LEFT_POSE_SHAPE_IDXS0))\n",
    "N_COLS = N_COLS + len(LEFT_POSE_SHAPE_IDXS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_COLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSE_OFFSET = START_IDX+21\n",
    "POSE_CENTER_IDXS0 = np.array([[POSE_OFFSET+11, POSE_OFFSET+12]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIPS_START: 0, LEFT_HAND_START: 40, RIGHT_HAND_START: 61, POSE_START: 61\n"
     ]
    }
   ],
   "source": [
    "LIPS_START = 0\n",
    "LEFT_HAND_START = LIPS_IDXS.size\n",
    "RIGHT_HAND_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n",
    "POSE_START = RIGHT_HAND_START + RIGHT_HAND_IDXS.size\n",
    "\n",
    "print(f'LIPS_START: {LIPS_START}, LEFT_HAND_START: {LEFT_HAND_START}, RIGHT_HAND_START: {RIGHT_HAND_START}, POSE_START: {POSE_START}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIPS_START: 0, LEFT_HAND_START: 40, RIGHT_HAND_START: 61, POSE_START: 61, HAND_BONE_START: 67, POSE_BONE_START: 88\n"
     ]
    }
   ],
   "source": [
    "# Bone\n",
    "HAND_BONE_START = POSE_START + POSE_IDXS.size\n",
    "POSE_BONE_START = HAND_BONE_START + LEFT_HAND_BONE_IDXS.size\n",
    "\n",
    "print(f'LIPS_START: {LIPS_START}, LEFT_HAND_START: {LEFT_HAND_START}, RIGHT_HAND_START: {RIGHT_HAND_START}, POSE_START: {POSE_START}, HAND_BONE_START: {HAND_BONE_START}, POSE_BONE_START: {POSE_BONE_START}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    'use_types': USE_TYPES,\n",
    "    'start_idx': START_IDX,\n",
    "    'lips_idxs0': LIPS_IDXS0,\n",
    "    'left_hand_idxs0': LEFT_HAND_IDXS0,\n",
    "    'right_hand_idxs0': RIGHT_HAND_IDXS0,\n",
    "    'left_pose_idxs0': LEFT_POSE_IDXS0,\n",
    "    'right_pose_idxs0': RIGHT_POSE_IDXS0,\n",
    "    'landmark_idxs_left_dominant0': LANDMARK_IDXS_LEFT_DOMINANT0,\n",
    "    'landmark_idxs_right_dominant0': LANDMARK_IDXS_RIGHT_DOMINANT0,\n",
    "    'hand_idxs0': HAND_IDXS0,\n",
    "    'n_cols': N_COLS,\n",
    "    'lips_idxs': LIPS_IDXS,\n",
    "    'left_hand_idxs': LEFT_HAND_IDXS,\n",
    "    'right_hand_idxs': RIGHT_HAND_IDXS,\n",
    "    'hand_idxs': HAND_IDXS,\n",
    "    'pose_idxs': POSE_IDXS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-04-30 09:53:25,160][__main__][<module>][INFO] {'use_types': ['left_hand', 'pose', 'right_hand'], 'start_idx': 468, 'lips_idxs0': array([ 61, 185,  40,  39,  37,   0, 267, 269, 270, 409, 291, 146,  91,\n",
      "       181,  84,  17, 314, 405, 321, 375,  78, 191,  80,  81,  82,  13,\n",
      "       312, 311, 310, 415,  95,  88, 178,  87,  14, 317, 402, 318, 324,\n",
      "       308]), 'left_hand_idxs0': array([468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488]), 'right_hand_idxs0': array([522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n",
      "       535, 536, 537, 538, 539, 540, 541, 542]), 'left_pose_idxs0': array([500, 502, 504, 506, 508, 510]), 'right_pose_idxs0': array([501, 503, 505, 507, 509, 511]), 'landmark_idxs_left_dominant0': array([ 61, 185,  40,  39,  37,   0, 267, 269, 270, 409, 291, 146,  91,\n",
      "       181,  84,  17, 314, 405, 321, 375,  78, 191,  80,  81,  82,  13,\n",
      "       312, 311, 310, 415,  95,  88, 178,  87,  14, 317, 402, 318, 324,\n",
      "       308, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
      "       480, 481, 482, 483, 484, 485, 486, 487, 488, 500, 502, 504, 506,\n",
      "       508, 510, 263, 249, 390, 373, 374, 380, 381, 382, 362, 466, 388,\n",
      "       387, 386, 385, 384, 398]), 'landmark_idxs_right_dominant0': array([ 61, 185,  40,  39,  37,   0, 267, 269, 270, 409, 291, 146,  91,\n",
      "       181,  84,  17, 314, 405, 321, 375,  78, 191,  80,  81,  82,  13,\n",
      "       312, 311, 310, 415,  95,  88, 178,  87,  14, 317, 402, 318, 324,\n",
      "       308, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533,\n",
      "       534, 535, 536, 537, 538, 539, 540, 541, 542, 501, 503, 505, 507,\n",
      "       509, 511,  33,   7, 163, 144, 145, 153, 154, 155, 133, 246, 161,\n",
      "       160, 159, 158, 157, 173]), 'hand_idxs0': array([468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 522, 523, 524, 525, 526,\n",
      "       527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539,\n",
      "       540, 541, 542]), 'n_cols': 368, 'lips_idxs': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39]), 'left_hand_idxs': array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56,\n",
      "       57, 58, 59, 60]), 'right_hand_idxs': array([], dtype=int64), 'hand_idxs': array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56,\n",
      "       57, 58, 59, 60]), 'pose_idxs': array([61, 62, 63, 64, 65, 66])}\n"
     ]
    }
   ],
   "source": [
    "logger.info(config2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "ROWS_PER_FRAME = 543  # number of landmarks per frame\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 09:53:25.306227: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 09:53:25.882066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22290 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:68:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Tensorflow layer to process data in TFLite\n",
    "    Data needs to be processed in the model itself, so we can not use Python\n",
    "\"\"\" \n",
    "def tf_acos(x):\n",
    "    negate = tf.cast(x < 0, dtype=tf.float32)\n",
    "    x = tf.abs(x)\n",
    "    ret = tf.constant(-0.0187293, dtype=tf.float32)\n",
    "    ret = ret * x\n",
    "    ret = ret + tf.constant(0.0742610, dtype=tf.float32)\n",
    "    ret = ret * x\n",
    "    ret = ret - tf.constant(0.2121144, dtype=tf.float32)\n",
    "    ret = ret * x\n",
    "    ret = ret + tf.constant(1.5707288, dtype=tf.float32)\n",
    "    ret = ret * tf.sqrt(1.0 - x)\n",
    "    ret = ret - 2 * negate * ret\n",
    "    return negate * tf.constant(3.14159265358979, dtype=tf.float32) + ret\n",
    "\n",
    "def angle_between_vectors_tf(v1, v2):\n",
    "    cos_theta = tf.math.divide_no_nan(tf.einsum('ij,ij->i', v1, v2),\n",
    "                                      (tf.norm(v1, axis=-1) * tf.norm(v2, axis=-1)))\n",
    "    return tf_acos(tf.clip_by_value(cos_theta, -1, 1))\n",
    "\n",
    "class PreprocessLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PreprocessLayer, self).__init__()\n",
    "        normalisation_correction = tf.constant([\n",
    "                    # Add 0.50 to left hand (original right hand) and substract 0.50 of right hand (original left hand)\n",
    "                    [0] * len(LIPS_IDXS) + [0.50] * len(LEFT_HAND_IDXS) + [0.50] * len(POSE_IDXS) + [0] * len(EYE_IDXS),\n",
    "                    # Y coordinates stay intact\n",
    "                    [0] * len(LANDMARK_IDXS_LEFT_DOMINANT0),\n",
    "                    # Z coordinates stay intact\n",
    "                    [0] * len(LANDMARK_IDXS_LEFT_DOMINANT0),\n",
    "                ],\n",
    "                dtype=tf.float32,\n",
    "            )\n",
    "        self.normalisation_correction = tf.transpose(normalisation_correction, [1, 0])\n",
    "        \n",
    "    def pad_edge(self, t, repeats, side):\n",
    "        if side == 'LEFT':\n",
    "            return tf.concat((tf.repeat(t[:1], repeats=repeats, axis=0), t), axis=0)\n",
    "        elif side == 'RIGHT':\n",
    "            return tf.concat((t, tf.repeat(t[-1:], repeats=repeats, axis=0)), axis=0)\n",
    "    \n",
    "    @tf.function(\n",
    "        input_signature=(tf.TensorSpec(shape=[None,N_ROWS,N_DIMS], dtype=tf.float32),),\n",
    "    )\n",
    "    def call(self, data0):\n",
    "        # normalize points\n",
    "        pose_center = (data0[:, POSE_OFFSET+11, :] + data0[:, POSE_OFFSET+12, :])/2\n",
    "        pose_center = tf.reshape(pose_center, [-1, 1, pose_center.shape[1]])\n",
    "        data0 = data0 - pose_center\n",
    "        \n",
    "        # Number of Frames in Video\n",
    "        N_FRAMES0 = tf.shape(data0)[0]\n",
    "        \n",
    "        # Find dominant hand by comparing summed absolute coordinates\n",
    "        left_hand_sum = tf.math.reduce_sum(tf.where(tf.math.is_nan(tf.gather(data0, LEFT_HAND_IDXS0, axis=1)), 0, 1))\n",
    "        right_hand_sum = tf.math.reduce_sum(tf.where(tf.math.is_nan(tf.gather(data0, RIGHT_HAND_IDXS0, axis=1)), 0, 1))\n",
    "        left_dominant = left_hand_sum >= right_hand_sum\n",
    "        \n",
    "        # Count non NaN Hand values in each frame for the dominant hand\n",
    "        if left_dominant:\n",
    "            frames_hands_non_nan_sum = tf.math.reduce_sum(\n",
    "                    tf.where(tf.math.is_nan(tf.gather(data0, LEFT_HAND_IDXS0, axis=1)), 0, 1),\n",
    "                    axis=[1, 2],\n",
    "                )\n",
    "        else:\n",
    "            frames_hands_non_nan_sum = tf.math.reduce_sum(\n",
    "                    tf.where(tf.math.is_nan(tf.gather(data0, RIGHT_HAND_IDXS0, axis=1)), 0, 1),\n",
    "                    axis=[1, 2],\n",
    "                )\n",
    "        \n",
    "        # Find frames indices with coordinates of dominant hand\n",
    "        non_empty_frames_idxs = tf.where(frames_hands_non_nan_sum > 0)\n",
    "        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n",
    "        # Filter frames\n",
    "        data = tf.gather(data0, non_empty_frames_idxs, axis=0)\n",
    "        \n",
    "        # Cast Indices in float32 to be compatible with Tensorflow Lite\n",
    "        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32)\n",
    "        # Normalize to start with 0\n",
    "        non_empty_frames_idxs -= tf.reduce_min(non_empty_frames_idxs)\n",
    "        \n",
    "        # Number of Frames in Filtered Video\n",
    "        N_FRAMES = tf.shape(data)[0]\n",
    "        \n",
    "        # Gather Relevant Landmark Columns\n",
    "        if left_dominant:\n",
    "            #######################################\n",
    "            # bone\n",
    "            #######################################\n",
    "            hand_bone = tf.expand_dims(data[:, LEFT_HAND_BONE_IDXS0[0][1]] - data[:, LEFT_HAND_BONE_IDXS0[0][0]], axis=1)\n",
    "            for i in range(1, len(LEFT_HAND_BONE_IDXS0)):\n",
    "                hand_bone = tf.concat([hand_bone, tf.expand_dims(data[:, LEFT_HAND_BONE_IDXS0[i][1]] - data[:, LEFT_HAND_BONE_IDXS0[i][0]], axis=1)], axis=1)\n",
    "                \n",
    "            pose_bone = tf.expand_dims(data[:, LEFT_POSE_BONE_IDXS0[0][1]] - data[:, LEFT_POSE_BONE_IDXS0[0][0]], axis=1)\n",
    "            for i in range(1, len(LEFT_POSE_BONE_IDXS0)):\n",
    "                pose_bone = tf.concat([pose_bone, tf.expand_dims(data[:, LEFT_POSE_BONE_IDXS0[i][1]] - data[:, LEFT_POSE_BONE_IDXS0[i][0]], axis=1)], axis=1)\n",
    "\n",
    "            hand_shape = tf.expand_dims(data[:, LEFT_HAND_SHAPE_IDXS0[0][1]] - data[:, LEFT_HAND_SHAPE_IDXS0[0][0]], axis=1)\n",
    "            for i in range(1, len(LEFT_HAND_SHAPE_IDXS0)):\n",
    "                hand_shape = tf.concat([hand_shape, tf.expand_dims(data[:, LEFT_HAND_SHAPE_IDXS0[i][1]] - data[:, LEFT_HAND_SHAPE_IDXS0[i][0]], axis=1)], axis=1)\n",
    "                \n",
    "            pose_shape = tf.expand_dims(data[:, LEFT_POSE_SHAPE_IDXS0[0][1]] - data[:, LEFT_POSE_SHAPE_IDXS0[0][0]], axis=1)\n",
    "            for i in range(1, len(LEFT_POSE_SHAPE_IDXS0)):\n",
    "                pose_shape = tf.concat([pose_shape, tf.expand_dims(data[:, LEFT_POSE_SHAPE_IDXS0[i][1]] - data[:, LEFT_POSE_SHAPE_IDXS0[i][0]], axis=1)], axis=1)\n",
    "            #######################################\n",
    "            # distance, angle, \n",
    "            #######################################\n",
    "            # drop Z...?   \n",
    "            # hand ----------\n",
    "            # dist\n",
    "            pose_data = data\n",
    "            hand_joint_distances = []\n",
    "            for i, j in LEFT_HAND_BONE_IDXS0:\n",
    "                hand_joint_distances.append(tf.norm(pose_data[:, i] - pose_data[:, j], axis=-1))\n",
    "            hand_joint_distances = tf.stack(hand_joint_distances, axis=-1)\n",
    "            hand_joint_distances = tf.expand_dims(hand_joint_distances, axis=-1) # [163, 33, 1]にする\n",
    "            hand_joint_distances = tf.tile(hand_joint_distances, [1, 1, 3]) # [163, 33, 3]にする\n",
    "            \n",
    "            # angle\n",
    "            hand_relative_angles = []\n",
    "            for (i1, j1), (i2, j2) in zip(LEFT_HAND_BONE_IDXS0[:-1], LEFT_HAND_BONE_IDXS0[1:]):\n",
    "                v1 = pose_data[:, i1] - pose_data[:, j1]\n",
    "                v2 = pose_data[:, i2] - pose_data[:, j2]\n",
    "\n",
    "                hand_relative_angles.append(angle_between_vectors_tf(v1, v2))\n",
    "            hand_relative_angles = tf.stack(hand_relative_angles, axis=-1)\n",
    "            hand_relative_angles = tf.expand_dims(hand_relative_angles, axis=-1) # [163, 33, 1]にする\n",
    "            hand_relative_angles = tf.tile(hand_relative_angles, [1, 1, 3]) # [163, 33, 3]にする            \n",
    "            \n",
    "            # body ----------\n",
    "            # dist\n",
    "            pose_data = data\n",
    "            pose_joint_distances = []\n",
    "            for i, j in LEFT_POSE_BONE_IDXS0:\n",
    "                pose_joint_distances.append(tf.norm(pose_data[:, i] - pose_data[:, j], axis=-1))\n",
    "            pose_joint_distances = tf.stack(pose_joint_distances, axis=-1)\n",
    "            pose_joint_distances = tf.expand_dims(pose_joint_distances, axis=-1) # [163, 33, 1]にする\n",
    "            pose_joint_distances = tf.tile(pose_joint_distances, [1, 1, 3]) # [163, 33, 3]にする         \n",
    "            \n",
    "            # angle\n",
    "            pose_relative_angles = []\n",
    "            for (i1, j1), (i2, j2) in zip(LEFT_POSE_BONE_IDXS0[:-1], LEFT_POSE_BONE_IDXS0[1:]):\n",
    "                v1 = pose_data[:, i1] - pose_data[:, j1]\n",
    "                v2 = pose_data[:, i2] - pose_data[:, j2]\n",
    "\n",
    "                pose_relative_angles.append(angle_between_vectors_tf(v1, v2))\n",
    "            pose_relative_angles = tf.stack(pose_relative_angles, axis=-1)    \n",
    "            pose_relative_angles = tf.expand_dims(pose_relative_angles, axis=-1) # [163, 33, 1]にする\n",
    "            pose_relative_angles = tf.tile(pose_relative_angles, [1, 1, 3]) # [163, 33, 3]にする     \n",
    "\n",
    "            #######################################\n",
    "            # angle motion\n",
    "            #######################################\n",
    "            if N_FRAMES > 1:\n",
    "                padded_hand_relative_angles_velocity_data = tf.pad(hand_relative_angles[1:] - hand_relative_angles[:-1], [[0, 1], [0, 0], [0, 0]], \"CONSTANT\", constant_values=np.NaN)\n",
    "            else:\n",
    "                padded_hand_relative_angles_velocity_data = tf.zeros_like(hand_relative_angles)\n",
    "            \n",
    "            if N_FRAMES > 1:\n",
    "                padded_pose_relative_angles_velocity_data = tf.pad(pose_relative_angles[1:] - pose_relative_angles[:-1], [[0, 1], [0, 0], [0, 0]], \"CONSTANT\", constant_values=np.NaN)\n",
    "            else:\n",
    "                padded_pose_relative_angles_velocity_data = tf.zeros_like(pose_relative_angles)\n",
    "                \n",
    "            #######################################\n",
    "            # pose 実行順番に注意。ここでdataが削減されます。\n",
    "            #######################################\n",
    "            data = tf.gather(data, LANDMARK_IDXS_LEFT_DOMINANT0, axis=1)\n",
    "            \n",
    "            #######################################\n",
    "            # motion\n",
    "            #######################################\n",
    "            if N_FRAMES > 1:\n",
    "                padded_velocity_data = tf.pad(data[1:] - data[:-1], [[0, 1], [0, 0], [0, 0]], \"CONSTANT\", constant_values=np.NaN)\n",
    "            else:\n",
    "                padded_velocity_data = tf.zeros_like(data)\n",
    "                \n",
    "            #######################################\n",
    "            # acceraration\n",
    "            #######################################\n",
    "            if N_FRAMES > 2:\n",
    "                acceleration_data = (data[1:] - data[:-1])[1:] - (data[1:] - data[:-1])[:-1]\n",
    "                padded_acceleration_data = tf.pad(acceleration_data, [[0, 2], [0, 0], [0, 0]], \"CONSTANT\", constant_values=np.NaN)\n",
    "            else:\n",
    "                padded_acceleration_data = tf.zeros_like(data)  \n",
    "                \n",
    "\n",
    "            \n",
    "            #######################################\n",
    "            # concat\n",
    "            #######################################\n",
    "            data = tf.concat([data,\n",
    "                              hand_bone, pose_bone, \n",
    "                              padded_velocity_data, padded_acceleration_data, \n",
    "                              hand_joint_distances, hand_relative_angles, \n",
    "                              pose_joint_distances, pose_relative_angles, \n",
    "                              padded_hand_relative_angles_velocity_data, \n",
    "                              padded_pose_relative_angles_velocity_data,\n",
    "                             hand_shape, pose_shape\n",
    "                             ], axis=1)\n",
    "            \n",
    "        else:\n",
    "            #######################################\n",
    "            # bone\n",
    "            #######################################\n",
    "            hand_bone = tf.expand_dims(data[:, RIGHT_HAND_BONE_IDXS0[0][1]] - data[:, RIGHT_HAND_BONE_IDXS0[0][0]], axis=1)\n",
    "            for i in range(1, len(RIGHT_HAND_BONE_IDXS0)):\n",
    "                hand_bone = tf.concat([hand_bone, tf.expand_dims(data[:, RIGHT_HAND_BONE_IDXS0[i][1]] - data[:, RIGHT_HAND_BONE_IDXS0[i][0]], axis=1)], axis=1)\n",
    "                \n",
    "            pose_bone = tf.expand_dims(data[:, RIGHT_POSE_BONE_IDXS0[0][1]] - data[:, RIGHT_POSE_BONE_IDXS0[0][0]], axis=1)\n",
    "            for i in range(1, len(RIGHT_POSE_BONE_IDXS0)):\n",
    "                pose_bone = tf.concat([pose_bone, tf.expand_dims(data[:, RIGHT_POSE_BONE_IDXS0[i][1]] - data[:, RIGHT_POSE_BONE_IDXS0[i][0]], axis=1)], axis=1)\n",
    "\n",
    "            hand_shape = tf.expand_dims(data[:, RIGHT_HAND_SHAPE_IDXS0[0][1]] - data[:, RIGHT_HAND_SHAPE_IDXS0[0][0]], axis=1)\n",
    "            for i in range(1, len(RIGHT_HAND_SHAPE_IDXS0)):\n",
    "                hand_shape = tf.concat([hand_shape, tf.expand_dims(data[:, RIGHT_HAND_SHAPE_IDXS0[i][1]] - data[:, RIGHT_HAND_SHAPE_IDXS0[i][0]], axis=1)], axis=1)\n",
    "                \n",
    "            pose_shape = tf.expand_dims(data[:, RIGHT_POSE_SHAPE_IDXS0[0][1]] - data[:, RIGHT_POSE_SHAPE_IDXS0[0][0]], axis=1)\n",
    "            for i in range(1, len(RIGHT_POSE_SHAPE_IDXS0)):\n",
    "                pose_shape = tf.concat([pose_shape, tf.expand_dims(data[:, RIGHT_POSE_SHAPE_IDXS0[i][1]] - data[:, RIGHT_POSE_SHAPE_IDXS0[i][0]], axis=1)], axis=1)\n",
    "                \n",
    "            hand_bone = hand_bone * tf.constant([-1., 1., 1.])\n",
    "            pose_bone = pose_bone * tf.constant([-1., 1., 1.])\n",
    "            hand_shape = hand_shape * tf.constant([-1., 1., 1.])\n",
    "            pose_shape = pose_shape * tf.constant([-1., 1., 1.])\n",
    "\n",
    "            #######################################\n",
    "            # distance, angle, \n",
    "            #######################################\n",
    "            # drop Z...?   \n",
    "            # hand ----------\n",
    "            # dist\n",
    "            pose_data = tf.identity(data)\n",
    "            pose_data = pose_data * tf.constant([-1., 1., 1.])\n",
    "            hand_joint_distances = []\n",
    "            for i, j in RIGHT_HAND_BONE_IDXS0:\n",
    "                hand_joint_distances.append(tf.norm(pose_data[:, i] - pose_data[:, j], axis=-1))\n",
    "            hand_joint_distances = tf.stack(hand_joint_distances, axis=-1)\n",
    "            hand_joint_distances = tf.expand_dims(hand_joint_distances, axis=-1) # [163, 33, 1]にする\n",
    "            hand_joint_distances = tf.tile(hand_joint_distances, [1, 1, 3]) # [163, 33, 3]にする\n",
    "            \n",
    "            # angle\n",
    "            hand_relative_angles = []\n",
    "            for (i1, j1), (i2, j2) in zip(RIGHT_HAND_BONE_IDXS0[:-1], RIGHT_HAND_BONE_IDXS0[1:]):\n",
    "                v1 = pose_data[:, i1] - pose_data[:, j1]\n",
    "                v2 = pose_data[:, i2] - pose_data[:, j2]\n",
    "\n",
    "                hand_relative_angles.append(angle_between_vectors_tf(v1, v2))\n",
    "            hand_relative_angles = tf.stack(hand_relative_angles, axis=-1)\n",
    "            hand_relative_angles = tf.expand_dims(hand_relative_angles, axis=-1) # [163, 33, 1]にする\n",
    "            hand_relative_angles = tf.tile(hand_relative_angles, [1, 1, 3]) # [163, 33, 3]にする            \n",
    "            \n",
    "            # body ----------\n",
    "            # dist\n",
    "            # pose_data = data\n",
    "            pose_joint_distances = []\n",
    "            for i, j in RIGHT_POSE_BONE_IDXS0:\n",
    "                pose_joint_distances.append(tf.norm(pose_data[:, i] - pose_data[:, j], axis=-1))\n",
    "            pose_joint_distances = tf.stack(pose_joint_distances, axis=-1)\n",
    "            pose_joint_distances = tf.expand_dims(pose_joint_distances, axis=-1) # [163, 33, 1]にする\n",
    "            pose_joint_distances = tf.tile(pose_joint_distances, [1, 1, 3]) # [163, 33, 3]にする         \n",
    "            \n",
    "            # angle\n",
    "            pose_relative_angles = []\n",
    "            for (i1, j1), (i2, j2) in zip(RIGHT_POSE_BONE_IDXS0[:-1], RIGHT_POSE_BONE_IDXS0[1:]):\n",
    "                v1 = pose_data[:, i1] - pose_data[:, j1]\n",
    "                v2 = pose_data[:, i2] - pose_data[:, j2]\n",
    "\n",
    "                pose_relative_angles.append(angle_between_vectors_tf(v1, v2))\n",
    "            pose_relative_angles = tf.stack(pose_relative_angles, axis=-1)    \n",
    "            pose_relative_angles = tf.expand_dims(pose_relative_angles, axis=-1) # [163, 33, 1]にする\n",
    "            pose_relative_angles = tf.tile(pose_relative_angles, [1, 1, 3]) # [163, 33, 3]にする     \n",
    "            \n",
    "            #######################################\n",
    "            # angle motion\n",
    "            #######################################\n",
    "            if N_FRAMES > 1:\n",
    "                padded_hand_relative_angles_velocity_data = tf.pad(hand_relative_angles[1:] - hand_relative_angles[:-1], [[0, 1], [0, 0], [0, 0]], \"CONSTANT\", constant_values=np.NaN)\n",
    "            else:\n",
    "                padded_hand_relative_angles_velocity_data = tf.zeros_like(hand_relative_angles)\n",
    "            \n",
    "            if N_FRAMES > 1:\n",
    "                padded_pose_relative_angles_velocity_data = tf.pad(pose_relative_angles[1:] - pose_relative_angles[:-1], [[0, 1], [0, 0], [0, 0]], \"CONSTANT\", constant_values=np.NaN)\n",
    "            else:\n",
    "                padded_pose_relative_angles_velocity_data = tf.zeros_like(pose_relative_angles)\n",
    "                \n",
    "            #######################################\n",
    "            # pose 実行順番に注意。ここでdataが削減されます。\n",
    "            #######################################\n",
    "            data = tf.gather(data, LANDMARK_IDXS_RIGHT_DOMINANT0, axis=1)\n",
    "            data = (\n",
    "                    self.normalisation_correction + (\n",
    "                        (data - self.normalisation_correction) * tf.where(self.normalisation_correction != 0, -1.0, 1.0))\n",
    "                )\n",
    "            \n",
    "            #######################################\n",
    "            # motion\n",
    "            #######################################\n",
    "            if N_FRAMES > 1:\n",
    "                padded_velocity_data = tf.pad(data[1:] - data[:-1], [[0, 1], [0, 0], [0, 0]], \"CONSTANT\", constant_values=np.NaN)\n",
    "            else:\n",
    "                padded_velocity_data = tf.zeros_like(data)\n",
    "                \n",
    "            #######################################\n",
    "            # acceraration\n",
    "            #######################################\n",
    "            if N_FRAMES > 2:\n",
    "                acceleration_data = (data[1:] - data[:-1])[1:] - (data[1:] - data[:-1])[:-1]\n",
    "                padded_acceleration_data = tf.pad(acceleration_data, [[0, 2], [0, 0], [0, 0]], \"CONSTANT\", constant_values=np.NaN)\n",
    "            else:\n",
    "                padded_acceleration_data = tf.zeros_like(data)    \n",
    "            \n",
    "                \n",
    "            #######################################\n",
    "            # concat\n",
    "            #######################################\n",
    "            data = tf.concat([data,\n",
    "                              hand_bone, pose_bone, \n",
    "                              padded_velocity_data, padded_acceleration_data, \n",
    "                              hand_joint_distances, hand_relative_angles, \n",
    "                              pose_joint_distances, pose_relative_angles, \n",
    "                              padded_hand_relative_angles_velocity_data, \n",
    "                              padded_pose_relative_angles_velocity_data,\n",
    "                             hand_shape, pose_shape\n",
    "                             ], axis=1)\n",
    "            \n",
    "            \n",
    "        #######################################\n",
    "        # resize\n",
    "        #######################################       \n",
    "        # Video fits in INPUT_SIZE\n",
    "        if N_FRAMES < INPUT_SIZE:\n",
    "            # Pad With -1 to indicate padding\n",
    "            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "            # Pad Data With Zeros\n",
    "            data = tf.pad(data, [[0, INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            return data, non_empty_frames_idxs\n",
    "        # Video needs to be downsampled to INPUT_SIZE\n",
    "        else:\n",
    "            # Repeat\n",
    "            if N_FRAMES < INPUT_SIZE**2:\n",
    "                repeats = tf.math.floordiv(INPUT_SIZE * INPUT_SIZE, N_FRAMES0)\n",
    "                data = tf.repeat(data, repeats=repeats, axis=0)\n",
    "                non_empty_frames_idxs = tf.repeat(non_empty_frames_idxs, repeats=repeats, axis=0)\n",
    "\n",
    "            # Pad To Multiple Of Input Size\n",
    "            pool_size = tf.math.floordiv(len(data), INPUT_SIZE)\n",
    "            if tf.math.mod(len(data), INPUT_SIZE) > 0:\n",
    "                pool_size += 1\n",
    "\n",
    "            if pool_size == 1:\n",
    "                pad_size = (pool_size * INPUT_SIZE) - len(data)\n",
    "            else:\n",
    "                pad_size = (pool_size * INPUT_SIZE) % len(data)\n",
    "\n",
    "            # Pad Start/End with Start/End value\n",
    "            pad_left = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(INPUT_SIZE, 2)\n",
    "            pad_right = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(INPUT_SIZE, 2)\n",
    "            if tf.math.mod(pad_size, 2) > 0:\n",
    "                pad_right += 1\n",
    "\n",
    "            # Pad By Concatenating Left/Right Edge Values\n",
    "            data = self.pad_edge(data, pad_left, 'LEFT')\n",
    "            data = self.pad_edge(data, pad_right, 'RIGHT')\n",
    "\n",
    "            # Pad Non Empty Frame Indices\n",
    "            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_left, 'LEFT')\n",
    "            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_right, 'RIGHT')\n",
    "\n",
    "            # Reshape to Mean Pool\n",
    "            data = tf.reshape(data, [INPUT_SIZE, -1, N_COLS, N_DIMS])\n",
    "            non_empty_frames_idxs = tf.reshape(non_empty_frames_idxs, [INPUT_SIZE, -1])\n",
    "\n",
    "            # Mean Pool\n",
    "            data = tf.experimental.numpy.nanmean(data, axis=1)\n",
    "            non_empty_frames_idxs = tf.experimental.numpy.nanmean(non_empty_frames_idxs, axis=1)\n",
    "\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            \n",
    "            return data, non_empty_frames_idxs\n",
    "    \n",
    "preprocess_layer = PreprocessLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目視確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/pvc-nfs-skobayashi/competition/kaggle/2023_kaggle_gislr/data/kaggle/train_landmark_files/26734/1001145816.parquet'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"file_path\"].iloc[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, non_empty_frame_idxs = get_data(\"/home/jovyan/pvc-nfs-skobayashi/competition/kaggle/2023_kaggle_gislr/data/kaggle/train_landmark_files/32319/1000278229.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def animation_frame_xy(f):\n",
    "#     frame = data[f]\n",
    "#     lip = frame[LIPS_START:LIPS_START+40,:]\n",
    "#     left = frame[40:61,:]\n",
    "#     pose = frame[61:, :]\n",
    "    \n",
    "#     ax.clear()\n",
    "#     ax.plot(lip[:,0], lip[:,1], '.')\n",
    "#     ax.plot(left[:,0], left[:,1], '.')\n",
    "#     ax.plot(pose[:,0], pose[:,1], '.')\n",
    "        \n",
    "#     plt.xlim(0, 1)\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.title(f\"frame:{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(f\"The sign being shown here is: {train_df[train_df.path==f'{path_to_sign}'].sign.values[0]}\")\n",
    "\n",
    "# ## These values set the limits on the graph to stabilize the video\n",
    "# xmin = np.nanmin(data[:,:,0])\n",
    "# xmax = np.nanmax(data[:,:,0])\n",
    "# ymin = np.nanmin(data[:,:,1])\n",
    "# ymax = np.nanmax(data[:,:,1])\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# l, = ax.plot([], [])\n",
    "# animation = FuncAnimation(fig, func=animation_frame_xy, frames=list(range(len(data))))\n",
    "# HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full dataset\n",
    "def preprocess_data():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n",
    "\n",
    "    # Fill X/y\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n",
    "        # Log message every 5000 samples\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        # Sanity check, data should not contain NaN values\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "\n",
    "    # Save X/y\n",
    "    np.save(f'{out_root}X.npy', X)\n",
    "    np.save(f'{out_root}y.npy', y)\n",
    "    np.save(F'{out_root}NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_row_parallel(row, right_handed=True):\n",
    "#     data, non_empty_frame_idxs = get_data(row[\"file_path\"])\n",
    "#     return data, row[\"sign_ord\"], non_empty_frame_idxs\n",
    "\n",
    "# def func_parallel(idx):\n",
    "#     row = train.iloc[idx]\n",
    "#     (x,y, non_empty) = convert_row_parallel(row)\n",
    "#     return [x,y, non_empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "\n",
    "# if not os.path.exists(f'{out_root}/X.npy'):     \n",
    "#     length =len(train)\n",
    "#     if False:\n",
    "#         with Pool(8) as pool:\n",
    "#             r = range(length)\n",
    "#             imap = pool.imap(func_parallel, r)\n",
    "#             result_all  = list(tqdm(imap, total=len(r)))        \n",
    "#     else:\n",
    "#         result_all = []\n",
    "#         for idx in tqdm(range(length)):\n",
    "#             metas = func_parallel(idx)\n",
    "#             result_all.append(metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(f'{out_root}/X.npy'):  \n",
    "#     X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
    "#     y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "#     NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n",
    "    \n",
    "#     for i, (x_,y_,z_) in tqdm(enumerate(result_all), total=len(result_all)):\n",
    "#         X[i,:] = x_\n",
    "#         y[i] = y_\n",
    "#         NON_EMPTY_FRAME_IDXS[i] = z_\n",
    "\n",
    "#     np.save(f'{out_root}X.npy', X)\n",
    "#     np.save(f'{out_root}y.npy', y)\n",
    "#     np.save(F'{out_root}NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026322126388549805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94477,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb29e3be0334171acc50868ec363942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0/94477\n",
      "Generated 5000/94477\n",
      "Generated 10000/94477\n",
      "Generated 15000/94477\n",
      "Generated 20000/94477\n",
      "Generated 25000/94477\n",
      "Generated 30000/94477\n",
      "Generated 35000/94477\n",
      "Generated 40000/94477\n",
      "Generated 45000/94477\n",
      "Generated 50000/94477\n",
      "Generated 55000/94477\n",
      "Generated 60000/94477\n",
      "Generated 65000/94477\n",
      "Generated 70000/94477\n",
      "Generated 75000/94477\n",
      "Generated 80000/94477\n",
      "Generated 85000/94477\n",
      "Generated 90000/94477\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(f'{out_root}/X.npy'):\n",
    "    preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID Intersection Train/Val: {37779, 61333, 36257, 49445, 37055, 32319, 16069, 34503, 22343, 55372, 30680, 27610, 25571, 18796, 26734, 4718, 28656, 53618, 29302, 2044, 62590}\n",
      "X_train shape: (75581, 32, 368, 3), X_val shape: (18896, 32, 368, 3)\n",
      "y_train shape: (75581,), y_val shape: (18896,)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(f'{out_root}/y_val.npy'):\n",
    "\n",
    "    # Save X/y\n",
    "    X = np.load(f'{out_root}/X.npy')\n",
    "    y = np.load(f'{out_root}/y.npy')\n",
    "    NON_EMPTY_FRAME_IDXS = np.load(f'{out_root}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "\n",
    "    # Save Train\n",
    "    X_train = X[train_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS[train_idxs]\n",
    "    y_train = y[train_idxs]\n",
    "    np.save(f'{out_root}/X_train.npy', X_train)\n",
    "    np.save(f'{out_root}/y_train.npy', y_train)\n",
    "    np.save(f'{out_root}/NON_EMPTY_FRAME_IDXS_TRAIN.npy', NON_EMPTY_FRAME_IDXS_TRAIN)\n",
    "\n",
    "    # Save Validation\n",
    "    X_val = X[val_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS[val_idxs]\n",
    "    y_val = y[val_idxs]\n",
    "    np.save(f'{out_root}/X_val.npy', X_val)\n",
    "    np.save(f'{out_root}/y_val.npy', y_val)\n",
    "    np.save(f'{out_root}/NON_EMPTY_FRAME_IDXS_VAL.npy', NON_EMPTY_FRAME_IDXS_VAL)\n",
    "\n",
    "    # Split Statistics\n",
    "    print(f'Patient ID Intersection Train/Val: {set(PARTICIPANT_IDS[train_idxs]).intersection(PARTICIPANT_IDS[val_idxs])}')\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n",
    "    print(f'y_train shape: {y_train.shape}, y_val shape: {y_val.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 水増し１"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanInterpolation(tf.keras.layers.Layer):\n",
    "    def __init__(self,  **kwargs):\n",
    "        super(NanInterpolation, self).__init__(**kwargs)\n",
    "        self.order = 3\n",
    "        self.limit = 3\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            # 入力データをNumpy配列に変換\n",
    "            data = inputs.numpy()\n",
    "\n",
    "            # 補間処理\n",
    "            interpolated_data = []\n",
    "            for i in range(data.shape[-1]):\n",
    "                df = pd.DataFrame(data[..., i])\n",
    "                # df = df.interpolate(method=\"spline\", order=self.order, limit=self.limit, limit_direction='both')\n",
    "                # df = df.interpolate(method=\"spline\", order=self.order, limit_direction='both')\n",
    "                df = df.interpolate(limit_direction='both')\n",
    "                # df.fillna(method=\"ffill\", inplace=True)   \n",
    "                # df.fillna(method=\"bfill\", inplace=True)\n",
    "                interpolated_data.append(df.to_numpy())\n",
    "\n",
    "            # 補間後のデータをテンソルに変換\n",
    "            result = np.stack(interpolated_data, axis=-1)\n",
    "            inputs = tf.convert_to_tensor(result, dtype=inputs.dtype)\n",
    "            \n",
    "        return inputs\n",
    "\n",
    "    \n",
    "class Scaling3D(tf.keras.layers.Layer):\n",
    "    def __init__(self, scale_range=(0.9, 1.1), **kwargs):\n",
    "        super(Scaling3D, self).__init__(**kwargs)\n",
    "        self.scale_range = scale_range\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            # ランダムなスケーリング係数を生成\n",
    "            scale_factor = tf.random.uniform(\n",
    "                (), minval=self.scale_range[0], maxval=self.scale_range[1]\n",
    "            )\n",
    "\n",
    "            # ポーズデータにスケーリング係数を適用\n",
    "            inputs = inputs * scale_factor\n",
    "\n",
    "        return inputs \n",
    "\n",
    "class TimeSeriesAugmentation(tf.keras.layers.Layer):\n",
    "    def __init__(self, framerate_factor_range=(0.8, 1.2),  **kwargs):\n",
    "        super(TimeSeriesAugmentation, self).__init__(**kwargs)\n",
    "        self.framerate_factor_range = framerate_factor_range\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            # フレームレート変更\n",
    "            framerate_factor = tf.random.uniform(\n",
    "                (), minval=self.framerate_factor_range[0], maxval=self.framerate_factor_range[1]\n",
    "            )\n",
    "            new_length = tf.cast(tf.cast(tf.shape(inputs)[0], tf.float32) * framerate_factor, tf.int32)\n",
    "            inputs_expanded = tf.expand_dims(inputs, axis=0)\n",
    "            resized_inputs = tf.image.resize(inputs_expanded, (new_length, tf.shape(inputs)[-2]))\n",
    "            inputs = resized_inputs[0]\n",
    "\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_root2 = out_root.replace(\"base\", \"augment\")\n",
    "os.makedirs(out_root2, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data2(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    \n",
    "    # augmentation\n",
    "    data = NanInterpolation()(data, training=True)\n",
    "    data = Scaling3D()(data, training=True)\n",
    "    data = TimeSeriesAugmentation()(data, training=True)\n",
    "    \n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_row_parallel(row, right_handed=True):\n",
    "#     data, non_empty_frame_idxs = get_data2(row[\"file_path\"])\n",
    "#     return data, row[\"sign_ord\"], non_empty_frame_idxs\n",
    "\n",
    "# def func_parallel(idx):\n",
    "#     row = train.iloc[idx]\n",
    "#     (x,y, non_empty) = convert_row_parallel(row)\n",
    "#     return [x,y, non_empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "\n",
    "# if not os.path.exists(f'{out_root2}/X.npy'):     \n",
    "#     length =len(train)\n",
    "#     if False:\n",
    "#         with Pool(8) as pool: #os.cpu_count()\n",
    "#             r = range(length)\n",
    "#             imap = pool.imap(func_parallel, r)\n",
    "#             result_all  = list(tqdm(imap, total=len(r)))        \n",
    "#     else:\n",
    "#         result_all = []\n",
    "#         for idx in tqdm(range(length)):\n",
    "#             metas = func_parallel(idx)\n",
    "#             result_all.append(metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(f'{out_root2}/X.npy'):  \n",
    "#     X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
    "#     y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "#     NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n",
    "    \n",
    "#     for i, (x_,y_,z_) in tqdm(enumerate(result_all), total=len(result_all)):\n",
    "#         X[i,:] = x_\n",
    "#         y[i] = y_\n",
    "#         NON_EMPTY_FRAME_IDXS[i] = z_\n",
    "\n",
    "#     np.save(f'{out_root2}X.npy', X)\n",
    "#     np.save(f'{out_root2}y.npy', y)\n",
    "#     np.save(F'{out_root2}NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full dataset\n",
    "def preprocess_data2():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n",
    "\n",
    "    # Fill X/y\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n",
    "        # Log message every 5000 samples\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data2(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        # Sanity check, data should not contain NaN values\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "\n",
    "    # Save X/y\n",
    "    np.save(f'{out_root2}X.npy', X)\n",
    "    np.save(f'{out_root2}y.npy', y)\n",
    "    np.save(F'{out_root2}NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.039018869400024414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94477,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f65ec0f70734fe694223eb0d013bb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0/94477\n",
      "Generated 5000/94477\n",
      "Generated 10000/94477\n",
      "Generated 15000/94477\n",
      "Generated 20000/94477\n",
      "Generated 25000/94477\n",
      "Generated 30000/94477\n",
      "Generated 35000/94477\n",
      "Generated 40000/94477\n",
      "Generated 45000/94477\n",
      "Generated 50000/94477\n",
      "Generated 55000/94477\n",
      "Generated 60000/94477\n",
      "Generated 65000/94477\n",
      "Generated 70000/94477\n",
      "Generated 75000/94477\n",
      "Generated 80000/94477\n",
      "Generated 85000/94477\n",
      "Generated 90000/94477\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(f'{out_root2}/X.npy'):\n",
    "    preprocess_data2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID Intersection Train/Val: {37779, 61333, 36257, 49445, 37055, 32319, 16069, 34503, 22343, 55372, 30680, 27610, 25571, 18796, 26734, 4718, 28656, 53618, 29302, 2044, 62590}\n",
      "X_train shape: (75581, 32, 368, 3), X_val shape: (18896, 32, 368, 3)\n",
      "y_train shape: (75581,), y_val shape: (18896,)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(f'{out_root2}/y_val.npy'):\n",
    "\n",
    "    # Save X/y\n",
    "    X = np.load(f'{out_root2}/X.npy')\n",
    "    y = np.load(f'{out_root2}/y.npy')\n",
    "    NON_EMPTY_FRAME_IDXS = np.load(f'{out_root}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "\n",
    "    # Save Train\n",
    "    X_train = X[train_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS[train_idxs]\n",
    "    y_train = y[train_idxs]\n",
    "    np.save(f'{out_root2}/X_train.npy', X_train)\n",
    "    np.save(f'{out_root2}/y_train.npy', y_train)\n",
    "    np.save(f'{out_root2}/NON_EMPTY_FRAME_IDXS_TRAIN.npy', NON_EMPTY_FRAME_IDXS_TRAIN)\n",
    "\n",
    "    # Save Validation\n",
    "    X_val = X[val_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS[val_idxs]\n",
    "    y_val = y[val_idxs]\n",
    "    np.save(f'{out_root2}/X_val.npy', X_val)\n",
    "    np.save(f'{out_root2}/y_val.npy', y_val)\n",
    "    np.save(f'{out_root2}/NON_EMPTY_FRAME_IDXS_VAL.npy', NON_EMPTY_FRAME_IDXS_VAL)\n",
    "\n",
    "    # Split Statistics\n",
    "    print(f'Patient ID Intersection Train/Val: {set(PARTICIPANT_IDS[train_idxs]).intersection(PARTICIPANT_IDS[val_idxs])}')\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n",
    "    print(f'y_train shape: {y_train.shape}, y_val shape: {y_val.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_70578/2103537015.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 水増し２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_root3 = out_root.replace(\"base\", \"augment_v02\")\n",
    "os.makedirs(out_root3, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    face: 0:468\n",
    "    left_hand: 468:489\n",
    "    pose: 489:522\n",
    "    right_hand: 522:544\n",
    "        \n",
    "\"\"\"\n",
    "def get_data3(file_path):\n",
    "    # Load Raw Data\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    \n",
    "    # augmentation\n",
    "    data = NanInterpolation()(data, training=True)\n",
    "    data = Scaling3D()(data, training=True)\n",
    "    data = TimeSeriesAugmentation()(data, training=True)\n",
    "    \n",
    "    # Process Data Using Tensorflow\n",
    "    data = preprocess_layer(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full dataset\n",
    "def preprocess_data3():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n",
    "\n",
    "    # Fill X/y\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n",
    "        # Log message every 5000 samples\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data3(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        # Sanity check, data should not contain NaN values\n",
    "        if np.isnan(data).sum() > 0:\n",
    "            print(row_idx)\n",
    "            return data\n",
    "\n",
    "    # Save X/y\n",
    "    np.save(f'{out_root3}X.npy', X)\n",
    "    np.save(f'{out_root3}y.npy', y)\n",
    "    np.save(F'{out_root3}NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{out_root3}/X.npy'):\n",
    "    preprocess_data3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{out_root3}/y_val.npy'):\n",
    "\n",
    "    # Save X/y\n",
    "    X = np.load(f'{out_root3}/X.npy')\n",
    "    y = np.load(f'{out_root3}/y.npy')\n",
    "    NON_EMPTY_FRAME_IDXS = np.load(f'{out_root}/NON_EMPTY_FRAME_IDXS.npy')\n",
    "\n",
    "    # Save Train\n",
    "    X_train = X[train_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS[train_idxs]\n",
    "    y_train = y[train_idxs]\n",
    "    np.save(f'{out_root3}/X_train.npy', X_train)\n",
    "    np.save(f'{out_root3}/y_train.npy', y_train)\n",
    "    np.save(f'{out_root3}/NON_EMPTY_FRAME_IDXS_TRAIN.npy', NON_EMPTY_FRAME_IDXS_TRAIN)\n",
    "\n",
    "    # Save Validation\n",
    "    X_val = X[val_idxs]\n",
    "    NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS[val_idxs]\n",
    "    y_val = y[val_idxs]\n",
    "    np.save(f'{out_root3}/X_val.npy', X_val)\n",
    "    np.save(f'{out_root3}/y_val.npy', y_val)\n",
    "    np.save(f'{out_root3}/NON_EMPTY_FRAME_IDXS_VAL.npy', NON_EMPTY_FRAME_IDXS_VAL)\n",
    "\n",
    "    # Split Statistics\n",
    "    print(f'Patient ID Intersection Train/Val: {set(PARTICIPANT_IDS[train_idxs]).intersection(PARTICIPANT_IDS[val_idxs])}')\n",
    "    print(f'X_train shape: {X_train.shape}, X_val shape: {X_val.shape}')\n",
    "    print(f'y_train shape: {y_train.shape}, y_val shape: {y_val.shape}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
